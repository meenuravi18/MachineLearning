{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1074928",
   "metadata": {},
   "source": [
    "## Assignment 3, April 23 2021\n",
    "### Meenu Ravi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f778d0",
   "metadata": {},
   "source": [
    "### Question 1: 10 points\n",
    "#### Train an SVM classifier on the MNIST dataset.  Experiment with one-versus-the-rest and one-vs-one strategies.  Which is faster for this problem?  Do theyachieve  similar  accuracy?   Tune  hyperparameters.   What  accuracy  can  youreach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a05524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "warnings. filterwarnings(\"ignore\") \n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2dc5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] # the data is already shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3768761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ae6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", LinearSVC(C=10, loss=\"hinge\",random_state=42,max_iter=7600))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daab8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf2 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", LinearSVC(C=10, loss=\"hinge\",random_state=42,max_iter=7600))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8267076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3488.736686229706"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "onevrest = OneVsRestClassifier(svm_clf)\n",
    "onevrest.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18979d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132\n"
     ]
    }
   ],
   "source": [
    "y_pred = onevrest.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1c9d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372.2875518798828"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "onevone = OneVsOneClassifier(svm_clf)\n",
    "onevone.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c049564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748\n"
     ]
    }
   ],
   "source": [
    "y_pred = onevone.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953f93a",
   "metadata": {},
   "source": [
    "One vs One is faster. For SVM, one vs one is preferred because  it is faster to train many classifiers on a smaller training set. They achieve very similar accuracies. However, the one v rest reaches an accuracy of around 91% while the one v one reaches an accuracy of around 97%. After tuning hyper parameters, this was the best accuracy I could achieve for both. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c111206",
   "metadata": {},
   "source": [
    "### Question 2: 10 points\n",
    "#### Train an SVM regressor on the California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4ea584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a97d4295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49420655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = housing[\"data\"], housing[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09507097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbef33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:16512], X[16512:], y[:16512], y[16512:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "702ef193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fabe0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6eab172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = LinearSVR(epsilon=1.5, random_state=42)\n",
    "svr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "612d1b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b26f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_support_vectors(svr, X, y):\n",
    "    y_pred = svr.predict(X)\n",
    "    off_margin = (np.abs(y - y_pred) >= svr.epsilon)\n",
    "    return np.argwhere(off_margin)\n",
    "\n",
    "svr.support_ = find_support_vectors(svr, X_train_scaled, y_train)\n",
    "\n",
    "eps_x1=X_train_scaled\n",
    "eps_y_pred = svr.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff70d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226108851447778"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_train, eps_y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faf61f",
   "metadata": {},
   "source": [
    "### Question 3: 20 points\n",
    "#### Train and fine-tune a Decision Tree for the moons dataset by following these\n",
    "#### steps:\n",
    "- Use make_moons(n_samples=10000, noise=0.4) to generate a moons\n",
    "dataset.\n",
    "- Use train_test_split() to split the dataset into a training set and a\n",
    "test set.\n",
    "- Use grid search with cross-validation (with the help of the GridSearchCV\n",
    "class) to find good hyperparameter values for a DecisionTreeClassifier .\n",
    "Hint: try various values for max_leaf_nodes.\n",
    "- Train it on the full training set using these hyperparameters, and measure\n",
    "your model’s performance on the test set. You should get roughly 85% to\n",
    "87% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98b3376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a22eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "590eaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         'min_samples_split': [2, 5, 8, 10]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_leaf_nodes': list(range(2, 50)), \n",
    "          'min_samples_split': [2, 5, 8, 10]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9552fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65e918b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862875"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=grid_search_cv.predict(X_train)\n",
    "accuracy_score(y_pred,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a873e79",
   "metadata": {},
   "source": [
    "### Question 4: 20 points\n",
    "#### Load the MNIST data and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for val idation, and 10,000 for testing). Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3278763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00ad09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b560cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "   X, y, test_size=10000, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92b67328",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31c5f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f41768d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_clf = ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "ext_clf.fit(X_train, y_train)\n",
    "y_pred_xt = ext_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b735ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6349fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf= LinearSVC(C=100, loss=\"hinge\",random_state=42,max_iter=7600)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63a6aaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dacda8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf), ('ext', ext_clf), ('svm', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96663a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rnd',\n",
       "                              RandomForestClassifier(max_leaf_nodes=16,\n",
       "                                                     n_estimators=500,\n",
       "                                                     random_state=42)),\n",
       "                             ('ext',\n",
       "                              ExtraTreesClassifier(max_leaf_nodes=16,\n",
       "                                                   n_estimators=500,\n",
       "                                                   random_state=42)),\n",
       "                             ('svm',\n",
       "                              LinearSVC(C=100, loss='hinge', max_iter=7600,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28671064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8343"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d94f97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rnd',\n",
       "                              RandomForestClassifier(max_leaf_nodes=16,\n",
       "                                                     n_estimators=500,\n",
       "                                                     random_state=42)),\n",
       "                             ('ext',\n",
       "                              ExtraTreesClassifier(max_leaf_nodes=16,\n",
       "                                                   n_estimators=500,\n",
       "                                                   random_state=42)),\n",
       "                             ('svm',\n",
       "                              LinearSVC(C=100, loss='hinge', max_iter=7600,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0f0fa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e3b3d",
   "metadata": {},
   "source": [
    "The voting classifier performs better than the random forest and the extra tree classifier. However, it performs a little worse or about the same as the SVM classifier and extra tree classifier. In the test set, the voting classifier performs really well. It reaches an accuracy rate of 85%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
